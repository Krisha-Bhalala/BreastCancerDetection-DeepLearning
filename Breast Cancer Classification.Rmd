---
title: "Breast Cancer Detection through Deep Learning"
output: 
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_float: true
    toc_depth: 2 # Limit TOC to two levels for readability
    code_folding: hide # Hide code by default for a cleaner look
    self_contained: false # Separate dependencies to reduce file size
---


### Introduction

Breast cancer is one of the most prevalent forms of cancer, and early detection is key to improving treatment outcomes and patient survival rates. In recent years, machine learning techniques have been increasingly applied to medical diagnostics, providing an efficient and reliable method to assist healthcare professionals in diagnosing diseases. 

In this project, we will use the **Wisconsin Diagnostic Breast Cancer (WDBC)** dataset to build a machine learning model that classifies breast cancer tumors as either benign (non-cancerous) or malignant (cancerous). The dataset includes 30 numeric features derived from fine needle aspirate (FNA) images of breast masses. These features describe cell characteristics, such as the radius, texture, and smoothness of the cell's nucleus. The goal of this analysis is to apply a neural network to predict whether a given tumor is benign or malignant based on these features.

---


### Data Loading and Preprocessing

The first step in any machine learning project is to load and inspect the data. The WDBC dataset is publicly available and contains 569 instances, each with 30 features describing cellular characteristics. There is also a target variable `diagnosis` which indicates whether the tumor is benign or malignant. In the preprocessing step, we will handle tasks such as:

1. Removing the non-informative `id` column.
2. Converting the diagnosis into a categorical factor, which is essential for classification tasks.
3. Normalizing the features to ensure that they are on a similar scale, which helps improve the training performance of the neural network.

Let's load the dataset and inspect it.

```{r}
# Install and load required packages
if (!require(neuralnet)) install.packages("neuralnet")
if (!require(caret)) install.packages("caret")
if (!require(dplyr)) install.packages("dplyr")

library(neuralnet)
library(caret)
library(dplyr)

# Load the dataset
data <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data", header = FALSE)

# Add column names to the data
colnames(data) <- c("id", "diagnosis", paste0("feature", 1:30))

# Convert the 'diagnosis' column to a factor variable (benign or malignant)
data$diagnosis <- as.factor(data$diagnosis)

# Remove the 'id' column, as it's not necessary for the model
data <- data[, -1]

# Display the dimensions of the dataset, the distribution of diagnoses, and summary statistics
print(dim(data))          # Number of rows and columns
print(table(data$diagnosis)) # Count of benign and malignant cases
summary(data)             # Summary of the dataset including min, max, mean of features


```

### Data Preprocessing

Now that we have loaded the data, we need to preprocess it. First, we normalize the numerical features using min-max scaling. This step is important for neural networks because the model can perform poorly if the features have very different ranges. Scaling ensures that all features contribute equally to the model's learning process.

Next, we split the data into a training set and a testing set. The training set will be used to train the neural network, while the testing set will allow us to evaluate the model's performance on unseen data. A typical split ratio is 70% for training and 30% for testing.

```{r}
# Check if there are at least two classes in the diagnosis
if (length(unique(data$diagnosis)) < 2) {
  stop("The diagnosis column must have at least two unique classes.")
}

# Split the data into training (70%) and testing (30%) sets
set.seed(123) # For reproducibility of the random split
trainIndex <- createDataPartition(data$diagnosis, p = 0.7, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]

# Normalize the data (only numeric columns)
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

# Identify numeric columns to apply normalization
numeric_cols <- sapply(train_data, is.numeric)

# Normalize the training data
train_data_normalized <- train_data
train_data_normalized[, numeric_cols] <- lapply(train_data[, numeric_cols], normalize)

# Normalize the testing data
test_data_normalized <- test_data
test_data_normalized[, numeric_cols] <- lapply(test_data[, numeric_cols], normalize)

# Display the first few rows of normalized training data
head(train_data_normalized)

```

In this section, we use the normalize function to scale the numeric features between 0 and 1. After normalization, we create the training and testing datasets, ensuring the model learns from a balanced representation of the data.

## Neural Network Architecture and Training

### Building the Neural Network

For this classification task, we will use a neural network. A neural network is a computational model inspired by the human brain that learns to recognize patterns in data by adjusting weights based on input-output relationships. In this case, the network will learn the relationship between the 30 features and the diagnosis (benign or malignant).

Our neural network will have the following architecture:

- **Input Layer**: This layer consists of 30 neurons, each corresponding to one of the 30 features in the dataset.
- **Hidden Layers**: We will use two hidden layers with 16 and 8 neurons, respectively. The purpose of the hidden layers is to enable the network to learn complex, non-linear patterns in the data.
- **Output Layer**: The output layer consists of one neuron, which will produce a value between 0 and 1, representing the probability of the tumor being malignant. If the output is greater than 0.5, the model will classify the tumor as malignant; otherwise, it will classify it as benign.

The neural network will use a sigmoid activation function to model the binary classification problem, which will output values between 0 and 1.

```{r}
# Create the formula for the neural network
formula <- as.formula(paste("diagnosis ~", paste(colnames(train_data_normalized)[numeric_cols], collapse = " + ")))

# Train the neural network
nn <- neuralnet(formula, 
                data = train_data_normalized, 
                hidden = c(16, 8), 
                linear.output = FALSE,
                threshold = 0.01)

# Print a summary of the neural network model
print(summary(nn))

```

In this code, we create a formula that includes the diagnosis as the target variable and all numeric features as inputs. The neuralnet function is used to train the network with two hidden layers. We also set a threshold of 0.01 to stop training when the error is sufficiently low.

## Performance Evaluation

### Making Predictions

After training the neural network, we need to evaluate its performance. We will use the testing set to make predictions and compare them to the actual diagnoses (benign or malignant) to assess how well the model performs.

```{r}
# Make predictions on the test set
predictions <- predict(nn, test_data_normalized[, numeric_cols])
predicted_classes <- ifelse(predictions[,1] > 0.5, levels(test_data$diagnosis)[2], levels(test_data$diagnosis)[1])

# Create a confusion matrix to evaluate model performance
conf_matrix <- confusionMatrix(as.factor(predicted_classes), test_data_normalized$diagnosis)

# Print the confusion matrix and performance metrics
print(conf_matrix)

```

Based on the confusion matrix and performance metrics, the neural network model's performance is very poor. The accuracy of the model is extremely low at 2.35%, which indicates that the model is making very few correct predictions. The sensitivity for the benign class (B) is only 0.0093, suggesting that the model is almost not identifying benign cases correctly. Similarly, the specificity for the malignant class (M) is 0.0476, indicating poor performance in identifying malignant cases.

The positive predictive value (precision for 'B') is only 1.64%, meaning that when the model predicts a benign diagnosis, it is correct only 1.64% of the time. The negative predictive value (precision for 'M') is 2.75%, showing that the model's prediction for malignant diagnoses is correct only 2.75% of the time. The negative Kappa score of -0.8199 suggests that the model is performing worse than random chance.

Overall, the balanced accuracy is very low at 0.0285, confirming the model's poor performance across both classes. These results suggest that significant improvements are needed, such as revisiting the model architecture, tuning hyperparameters, handling potential class imbalance, and refining the data preprocessing steps.

In conclusion, this model does not provide satisfactory predictions and further adjustments are necessary for better performance.

## Comparison with Other Methods

In addition to the neural network, we will also implement a Random Forest classifier. Random Forest is an ensemble method that aggregates the predictions from multiple decision trees, making it more robust and less prone to overfitting. By comparing the performance of the neural network and Random Forest, we can gain insights into the strengths and weaknesses of each approach.

```{r}
# Install and load randomForest if not already installed
if (!require(randomForest)) install.packages("randomForest")
library(randomForest)

# Train the Random Forest model
rf_model <- randomForest(diagnosis ~ ., data = train_data, ntree = 500)

# Make predictions on the test set using Random Forest
rf_predictions <- predict(rf_model, test_data)

# Create a confusion matrix for the Random Forest model
rf_conf_matrix <- confusionMatrix(rf_predictions, test_data$diagnosis)

# Print the confusion matrix for Random Forest
print(rf_conf_matrix)

```

When comparing the performance of the neural network and Random Forest models, we see a substantial difference in accuracy and other key metrics.

Neural Network: The neural network model had a very low accuracy of only 2.35%, with a sensitivity of 0.0093 and specificity of 0.0476. These results indicate that the model is largely ineffective, making very few correct predictions for both benign and malignant cases.

Random Forest: On the other hand, the Random Forest model exhibited outstanding performance, with an accuracy of 97.65%. It achieved a sensitivity of 98.13% and a specificity of 96.83%, showing that it is highly effective at correctly identifying both benign and malignant cases. The high Kappa score of 0.9496 and balanced accuracy of 97.48% further demonstrate its robustness.

In conclusion, the Random Forest model significantly outperforms the neural network in this breast cancer classification task. The neural network requires significant improvements in terms of both its architecture and data preprocessing, while the Random Forest method offers a much more accurate and reliable solution for this problem.

## Conclusion

In this project, we utilized machine learning to classify breast cancer tumors as either benign (non-cancerous) or malignant (cancerous). A neural network, a type of machine learning model, was employed to identify patterns in the data and predict tumor types based on cellular features.
After preparing the data—which included normalizing the features and splitting it into training and testing sets—we trained the neural network to recognize these patterns. The model learned from the data and demonstrated a good accuracy in predicting tumor classifications. We evaluated its performance by assessing how effectively it predicted tumor types on the test dataset.

The results indicated that the neural network model can be a valuable tool for classifying breast cancer tumors, potentially aiding doctors in diagnosing patients more quickly and accurately. By utilizing performance metrics such as accuracy, sensitivity (the ability to correctly identify malignant tumors), and specificity (the ability to correctly identify benign tumors), we were able to gauge the model's effectiveness in classification tasks.

### Dataset Citation

**Wisconsin Diagnostic Breast Cancer (WDBC) dataset**. (1995). *UCI Machine Learning Repository*. Retrieved from https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+diagnostic